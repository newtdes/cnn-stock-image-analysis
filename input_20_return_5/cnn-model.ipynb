{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All files are here\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We write a function to convert the images folder to .dat type\n",
    "def images_to_dat(images_folder, output_file):\n",
    "    with open(output_file, \"wb\") as dat_file:\n",
    "        for filename in sorted([f for f in os.listdir(images_folder) if f != \"output.csv\" and f.endswith(\".jpeg\")], key = lambda x: int(x.split('_')[0])):\n",
    "        # for filename in os.listdir(images_folder):\n",
    "            if filename.endswith(\".jpeg\"):\n",
    "            # Read the image file\n",
    "                img_path = os.path.join(images_folder, filename)\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    print(f\"Failed to load {filename}\")\n",
    "                    continue \n",
    "                img = img > 32\n",
    "                img = img.astype(np.uint8) * 255\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "                img_array = np.array(img)\n",
    "\n",
    "                # Flatten the image and convert to bytes, for easier storage\n",
    "                image_bytes = img_array.flatten().tobytes()\n",
    "\n",
    "                # Write the image data and store that in .dat file\n",
    "                dat_file.write(image_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function\n",
    "images_to_dat(\"training_data\", \"training_data.dat\")\n",
    "images_to_dat(\"validation_data\", \"validation_data.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(287102, 64, 60)\n"
     ]
    }
   ],
   "source": [
    "# We then create an array of images\n",
    "# This is a breakthrough, at least for me, since I cannot do anything to store a large amount like that\n",
    "# to a list, until I find np.memmap\n",
    "training_data = []\n",
    "training_data.append(np.memmap(\"training_data.dat\", dtype = np.uint8, mode = 'r').reshape(\n",
    "                        (-1, 64, 60))) # since it is 60 x 60 images\n",
    "training_data = np.concatenate(training_data)\n",
    "print(training_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123045, 64, 60)\n"
     ]
    }
   ],
   "source": [
    "# Similarly, for validation_data\n",
    "validation_data = []\n",
    "validation_data.append(np.memmap(\"validation_data.dat\", dtype = np.uint8, mode = 'r').reshape(\n",
    "    (-1, 64, 60)))\n",
    "validation_data = np.concatenate(validation_data)\n",
    "print(validation_data.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f1062708a37074d70712b695aadee582e0b0b9f95f45576b5521424137d05fec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
